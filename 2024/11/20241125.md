<head><meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" /><meta charset="UTF-8"></head>

# 20241125 â—‹

I'm too sleepy... maybe I'm hibernating

- printed some research papers to read when I get bored this week
- browsed API requests/responses of GitHub

## "Measuring the Effects of Autonomous Mobile Robot on Pedestrian Behavior"

They propose this method: first, they get pedestrians' trajectory data under two scenarios: one is an auto robot present, and he other is an auto robot absent, and then, they compare parameters modeled with the Social Force Model to see the effect of a robot's presence on human behaviors.

They performed 20 sets of experiments with 15 people. I will ask the author about her experience with the experiments next time I see her.

## LightRAG

[LightRAG: Simple and Fast Retrieval-Augmented Generation](https://arxiv.org/abs/2410.05779)

My friend, who is pursuing a Ph.D. in AI, says that the AI field is evolving so quickly that researchers don't wait for journals to accept their papers. Instead, they publish them on arXiv to share their work with others as soon as possible. I'm not sure it's 100% true, but it makes sense.

This might be the case for this paper; I only find this paper on arXiv now.

It seems LightRAG is a (sort of) improved version of GraphRAG, so I need to check it first.

### GraphRAG

[From Local to Global: A Graph RAG Approach to Query-Focused Summarization](https://arxiv.org/abs/2404.16130)

[Welcome - GraphRAG](https://microsoft.github.io/graphrag/)

> GraphRAG is a structured, hierarchical approach to Retrieval Augmented Generation (RAG), as opposed to naive semantic-search approaches using plain text snippets. The GraphRAG process involves extracting a knowledge graph out of raw text, building a community hierarchy, generating summaries for these communities, and then leveraging these structures when perform RAG-based tasks.

I worked on simple RAG systems in the past, and from my experience, I feel that the knowledge stored in the database is very independent and fractured with a simple RAG.

GraphRAG addresses the problem by constructing a graph to take relationships/relevance between knowledge into account.

### [gusye1234/nano-graphrag](https://github.com/gusye1234/nano-graphrag)

> ðŸ˜­ [GraphRAG](https://arxiv.org/pdf/2404.16130) is good and powerful, but the official [implementation](https://github.com/microsoft/graphrag/tree/main) is difficult/painful to read or hack.

> ðŸ˜Š This project provides a smaller, faster, cleaner GraphRAG, while remaining the core functionality.

And, this implementation seems to be used in the LightRAG implementation

### [HKUDS/LightRAG](https://github.com/HKUDS/LightRAG)

Disclaimer: I'm not an AI researcher, and my initial understanding must be incorrect.

It's impressive that the GitHub repository has around 10k stars even though the paper and the repo have been published last month (arXiv: Oct 8 2024). My guess is that the LightRAG is trending in the space.

I skimmed the paper and the repository, but I could not understand what makes LightRAG special than GraphRAG (maybe I lack the fundamental knowledge), but as the figure 1 suggests, the approach consists of graph-based text indexing and dual-level retrieval paradigm (using both low-level keys and high-level keys).

Since the implementation just emerged last month, I'm reluctant to use it in production. I think we can wait for a bit and see if there are real-life adaptions.

---

Eggs 300
Protein bar 200
Gummies 300
Yogurt 500
Udon 500
Bagel 250
Muffin 250

Total 2300 kcal

---

MUST:

- Browse [andrewyng/aisuite](https://github.com/andrewyng/aisuite)
- Rayan Programming Contest 2024 (20241130)
- Resume measuring my weight (20241201)

TODO:

- Bring books from my parents' house (20241128)
- Upgrade the Amazon Lightsail plan (take a snapshot, create a new instance, and migrate)

---

[index](../../index.html)
[20241124](20241124.html)
[20241126](20241126.html)
